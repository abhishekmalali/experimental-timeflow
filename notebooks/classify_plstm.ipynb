{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "from tensorflow.python.ops.rnn_cell import LSTMCell, GRUCell\n",
    "from PhasedLSTMCell import PhasedLSTMCell, multiPLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flags = tf.flags\n",
    "flags.DEFINE_string(\"unit\", \"PLSTM\", \"Can be PSLTM, LSTM, GRU\")\n",
    "flags.DEFINE_integer(\"n_hidden\", 100, \"hidden units in the recurrent layer\")\n",
    "flags.DEFINE_integer(\"n_epochs\", 30, \"number of epochs\")\n",
    "flags.DEFINE_integer(\"batch_size\", 32, \"batch size\")\n",
    "flags.DEFINE_integer(\"b_per_epoch\", 80, \"batches per epoch\")\n",
    "flags.DEFINE_integer(\"n_layers\", 4, \"hidden units in the recurrent layer\")\n",
    "flags.DEFINE_float(\"exp_init\", 3., \"Value for initialization of Tau\")\n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Net Params\n",
    "n_input = 1\n",
    "n_out = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RNN(_X, _weights, _biases, lens):\n",
    "    if FLAGS.unit == \"PLSTM\":\n",
    "        cell = PhasedLSTMCell(FLAGS.n_hidden, use_peepholes=True, state_is_tuple=True)\n",
    "    elif FLAGS.unit == \"GRU\":\n",
    "        cell = GRUCell(FLAGS.n_hidden)\n",
    "    elif FLAGS.unit == \"LSTM\":\n",
    "        cell = LSTMCell(FLAGS.n_hidden, use_peepholes=True, state_is_tuple=True)\n",
    "    else:\n",
    "        raise ValueError(\"Unit '{}' not implemented.\".format(FLAGS.unit))\n",
    "    initial_states = [tf.nn.rnn_cell.LSTMStateTuple(tf.zeros([FLAGS.batch_size, FLAGS.n_hidden], tf.float32), tf.zeros([FLAGS.batch_size, FLAGS.n_hidden], tf.float32)) for _ in range(FLAGS.n_layers)]\n",
    "    outputs, initial_states = multiPLSTM(_X, FLAGS.batch_size, lens, FLAGS.n_layers, FLAGS.n_hidden, n_input, initial_states)\n",
    "\n",
    "    outputs = tf.slice(outputs, [0, 0, 0], [-1, -1, FLAGS.n_hidden])\n",
    "    \n",
    "    batch_size = tf.shape(outputs)[0]\n",
    "    max_len = tf.shape(outputs)[1]\n",
    "    out_size = int(outputs.get_shape()[2])\n",
    "    index = tf.range(0, batch_size) * max_len + (lens - 1)\n",
    "    flat = tf.reshape(outputs, [-1, out_size])\n",
    "    relevant = tf.gather(flat, index)\n",
    "\n",
    "    return tf.nn.bias_add(tf.matmul(relevant, _weights['out']), _biases['out']), initial_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the PLSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Compiling RNN...',)\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, [None, None, n_input + 1])\n",
    "lens = tf.placeholder(tf.int32, [None])\n",
    "#labels\n",
    "y = tf.placeholder(tf.float32, [None, 2])\n",
    "# weights from input to hidden\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([FLAGS.n_hidden, n_out], dtype=tf.float32))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([n_out], dtype=tf.float32))\n",
    "}\n",
    "\n",
    "# Register weights to be monitored by tensorboard\n",
    "w_out_hist = tf.summary.histogram(\"weights_out\", weights['out'])\n",
    "b_out_hist = tf.summary.histogram(\"biases_out\", biases['out'])\n",
    "print (\"Compiling RNN...\",)\n",
    "predictions, initial_states = RNN(x, weights, biases, lens)\n",
    "print (\"DONE!\")\n",
    "# Register initial_states to be monitored by tensorboard\n",
    "initial_states_hist = tf.summary.histogram(\"initial_states\", initial_states[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Compiling cost functions...',)\n",
      "DONE!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhishek/anaconda/envs/tflow/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py:91: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "print (\"Compiling cost functions...\",)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(predictions, y))\n",
    "print (\"DONE!\")\n",
    "cost_summary = tf.summary.scalar(\"cost\", cost)\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluation\n",
    "correct_pred = tf.equal(tf.argmax(predictions, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "accuracy_summary = tf.summary.scalar(\"accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_random_batch(batch_size):\n",
    "    file_index = np.random.choice(range(1, 1001), size=batch_size)\n",
    "    file_dir = '../data/classify/train/'\n",
    "    file_values = []\n",
    "    len_values = []\n",
    "    Y = np.zeros((batch_size, n_out))\n",
    "    for j in range(len(file_index)):\n",
    "        out = np.loadtxt(file_dir + str(file_index[j]) + '.csv', delimiter=',')\n",
    "        file_values.append(out)\n",
    "        len_values.append(len(out))\n",
    "        if file_index[j] > 500:\n",
    "            Y[j, 1] = 1\n",
    "        else:\n",
    "            Y[j, 0] = 1\n",
    "    max_len = np.max(len_values)\n",
    "    X = np.zeros((batch_size, max_len, n_input+1))\n",
    "    for i in range(len(file_values)):\n",
    "        X[i, max_len-len_values[i]:, :] = np.array(file_values[i])\n",
    "        \n",
    "    return X, Y, np.array(len_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Initializing variables...',)\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "print (\"Initializing variables...\",)\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter(\"/tmp/run/1\", sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|â–Ž         | 2/80 [00:59<39:26, 30.33s/it]"
     ]
    }
   ],
   "source": [
    "for step in range(FLAGS.n_epochs):\n",
    "    train_cost = 0\n",
    "    train_acc = 0\n",
    "    for i in tqdm(range(FLAGS.b_per_epoch)):\n",
    "        batch_xs, batch_ys, leng = create_random_batch(FLAGS.batch_size)\n",
    "        res = sess.run([optimizer, cost, accuracy],\n",
    "                       feed_dict={x: batch_xs,\n",
    "                                  y: batch_ys,\n",
    "                                  lens: leng\n",
    "                                  })\n",
    "        train_cost += res[1] / FLAGS.b_per_epoch\n",
    "        train_acc += res[2] / FLAGS.b_per_epoch\n",
    "    print \"Epoch \"+ str(i+1) +\" train_cost: \"+str(train_cost)+\" train_accuracy: \"+str(train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
