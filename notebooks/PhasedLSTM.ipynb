{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/abhishek/Projects/experimental-timeflow/')\n",
    "import timeflow as tflow\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import clip_ops\n",
    "from tensorflow.python.ops import init_ops\n",
    "from tensorflow.python.ops import nn_ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops.math_ops import sigmoid\n",
    "from tensorflow.python.ops.math_ops import tanh\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import variable_scope as vs\n",
    "from tensorflow.python.ops.rnn_cell import RNNCell, LSTMStateTuple\n",
    "from tensorflow.python.platform import tf_logging as logging\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow.python.ops import random_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_exp_initializer(minval=0, maxval=None, seed=None,\n",
    "                               dtype=dtypes.float32):\n",
    "    \"\"\"Returns an initializer that generates tensors with an exponential distribution.\n",
    "\n",
    "    Args:\n",
    "      minval: A python scalar or a scalar tensor. Lower bound of the range\n",
    "        of random values to generate.\n",
    "      maxval: A python scalar or a scalar tensor. Upper bound of the range\n",
    "        of random values to generate.  Defaults to 1 for float types.\n",
    "      seed: A Python integer. Used to create random seeds. See\n",
    "        [`set_random_seed`](../../api_docs/python/constant_op.md#set_random_seed)\n",
    "        for behavior.\n",
    "      dtype: The data type.\n",
    "\n",
    "    Returns:\n",
    "      An initializer that generates tensors with an exponential distribution.\n",
    "    \"\"\"\n",
    "\n",
    "    def _initializer(shape, dtype=dtype, partition_info=None):\n",
    "        return tf.exp(random_ops.random_uniform(shape, minval, maxval, dtype, seed=seed))\n",
    "\n",
    "    return _initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PhasedLSTMCell():\n",
    "    \n",
    "    def __init__(self, inputs, num_units, alpha=0.001, r_on_init=0.05, tau_init=6.):\n",
    "        self._num_units = num_units\n",
    "        self.alpha = alpha\n",
    "        self.r_on_init = r_on_init\n",
    "        self.tau_init = tau_init\n",
    "        \n",
    "        \n",
    "        #Building the graph\n",
    "        dtype = input_layer.dtype\n",
    "        #Initializing the kronos gate variables\n",
    "        self.tau = vs.get_variable(\n",
    "                \"T\", shape=[self._num_units],\n",
    "                initializer=random_exp_initializer(0, self.tau_init), dtype=dtype)\n",
    "\n",
    "        self.r_on = vs.get_variable(\n",
    "            \"R\", shape=[self._num_units],\n",
    "            initializer=init_ops.constant_initializer(self.r_on_init), dtype=dtype)\n",
    "\n",
    "        self.s = vs.get_variable(\n",
    "            \"S\", shape=[self._num_units],\n",
    "            initializer=init_ops.random_uniform_initializer(0., self.tau.initialized_value()), dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTMLayerBatch(object):\n",
    "\n",
    "    def __init__(self, input_size, hidden_layer_size, input_placeholder):\n",
    "\n",
    "        # Initialization of given values\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.target_size = target_size\n",
    "\n",
    "        # Weights and Bias for input and hidden tensor\n",
    "        self.Wi = tf.Variable(tf.zeros(\n",
    "            [self.input_size, self.hidden_layer_size]))\n",
    "        self.Ui = tf.Variable(tf.zeros(\n",
    "            [self.hidden_layer_size, self.hidden_layer_size]))\n",
    "        self.bi = tf.Variable(tf.zeros([self.hidden_layer_size]))\n",
    "\n",
    "        \n",
    "        self.Wf = tf.Variable(tf.zeros(\n",
    "            [self.input_size, self.hidden_layer_size]))\n",
    "        self.Uf = tf.Variable(tf.zeros(\n",
    "            [self.hidden_layer_size, self.hidden_layer_size]))\n",
    "        self.bf = tf.Variable(tf.zeros([self.hidden_layer_size]))        \n",
    "        \n",
    "        \n",
    "        self.Wog = tf.Variable(tf.zeros(\n",
    "            [self.input_size, self.hidden_layer_size]))\n",
    "        self.Uog = tf.Variable(tf.zeros(\n",
    "            [self.hidden_layer_size, self.hidden_layer_size]))\n",
    "        self.bog = tf.Variable(tf.zeros([self.hidden_layer_size]))        \n",
    "        \n",
    "        \n",
    "        self.Wc = tf.Variable(tf.zeros(\n",
    "            [self.input_size, self.hidden_layer_size]))\n",
    "        self.Uc = tf.Variable(tf.zeros(\n",
    "            [self.hidden_layer_size, self.hidden_layer_size]))\n",
    "        self.bc = tf.Variable(tf.zeros([self.hidden_layer_size]))        \n",
    "        \n",
    "        # Placeholder for input vector with shape[batch, seq, embeddings]\n",
    "        self._inputs = input_placeholder\n",
    "\n",
    "        # Processing inputs to work with scan function\n",
    "        self.processed_input = process_batch_input_for_RNN(self._inputs)\n",
    "        \n",
    "        self.initial_hidden = self._inputs[:, 0, :]\n",
    "        self.initial_hidden= tf.matmul(\n",
    "            self.initial_hidden, tf.zeros([input_size, hidden_layer_size]))\n",
    "        \n",
    "        \n",
    "        self.initial_hidden=tf.pack([self.initial_hidden,self.initial_hidden])\n",
    "        \n",
    "    # Function for LSTM cell.\n",
    "    def forward_step(self, previous_hidden_memory_tuple, x):\n",
    "        \"\"\"\n",
    "        This function takes previous hidden state and memory tuple with input and\n",
    "        outputs current hidden state.\n",
    "        \"\"\"\n",
    "        \n",
    "        previous_hidden_state,c_prev=tf.unpack(previous_hidden_memory_tuple)\n",
    "        \n",
    "        #Input Gate\n",
    "        i= tf.sigmoid(\n",
    "            tf.matmul(x,self.Wi)+tf.matmul(previous_hidden_state,self.Ui) + self.bi \n",
    "        )\n",
    "        \n",
    "        #Forget Gate\n",
    "        f= tf.sigmoid(\n",
    "            tf.matmul(x,self.Wf)+tf.matmul(previous_hidden_state,self.Uf) + self.bf \n",
    "        )\n",
    "        \n",
    "        #Output Gate\n",
    "        o= tf.sigmoid(\n",
    "            tf.matmul(x,self.Wog)+tf.matmul(previous_hidden_state,self.Uog) + self.bog\n",
    "        )\n",
    "        \n",
    "        #New Memory Cell\n",
    "        c_= tf.nn.tanh(\n",
    "            tf.matmul(x,self.Wc)+tf.matmul(previous_hidden_state,self.Uc) + self.bc \n",
    "        ) \n",
    "        \n",
    "        #Final Memory cell\n",
    "        c= f*c_prev + i*c_\n",
    "        \n",
    "        #Current Hidden state\n",
    "        current_hidden_state = o*tf.nn.tanh(c)\n",
    "\n",
    "\n",
    "        return tf.pack([current_hidden_state,c])\n",
    "\n",
    "    # Function for getting all hidden state.\n",
    "    def get_outputs(self):\n",
    "        \"\"\"\n",
    "        Iterates through time/ sequence to get all hidden state\n",
    "        \"\"\"\n",
    "\n",
    "        # Getting all hidden state throuh time\n",
    "        all_hidden_states = tf.scan(self.forward_step,\n",
    "                                    self.processed_input,\n",
    "                                    initializer=self.initial_hidden,\n",
    "                                    name='states')\n",
    "        all_hidden_states=all_hidden_states[:,0,:,:]\n",
    "        \n",
    "        return all_hidden_states\n",
    "\n",
    "# Function to convert batch input data to use scan ops of tensorflow.\n",
    "def process_batch_input_for_RNN(batch_input):\n",
    "    \"\"\"\n",
    "    Process tensor of size [5,3,2] to [3,5,2]\n",
    "    \"\"\"\n",
    "    batch_input_ = tf.transpose(batch_input, perm=[2, 0, 1])\n",
    "    X = tf.transpose(batch_input_)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synthetic data from NIPS2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_async_sin(async_sampling, resolution=None, batch_size=32, on_target_T=(5, 6), off_target_T=(1, 100),\n",
    "                  max_len=125, min_len=85):\n",
    "    half_batch = int(batch_size / 2)\n",
    "    full_length = off_target_T[1] - on_target_T[1] + on_target_T[0] - off_target_T[0]\n",
    "    \n",
    "    # generate random periods\n",
    "    posTs = np.random.uniform(on_target_T[0], on_target_T[1], half_batch)\n",
    "    size_low = np.floor((on_target_T[0] - off_target_T[0]) * half_batch / full_length).astype('int32')\n",
    "    size_high = np.ceil((off_target_T[1] - on_target_T[1]) * half_batch / full_length).astype('int32')\n",
    "    low_vec = np.random.uniform(off_target_T[0], on_target_T[0], size_low)\n",
    "    high_vec = np.random.uniform(on_target_T[1], off_target_T[1], size_high+1)\n",
    "    \n",
    "    negTs = np.hstack([low_vec,\n",
    "                       high_vec])\n",
    "    # generate random lengths\n",
    "    if async_sampling:\n",
    "        lens = np.random.uniform(min_len, max_len, batch_size)\n",
    "    else:\n",
    "        max_len *= int(1 / resolution)\n",
    "        min_len *= int(1 / resolution)\n",
    "        lens = np.random.uniform(min_len, max_len, batch_size)\n",
    "    # generate random number of samples\n",
    "    if async_sampling:\n",
    "        samples = np.random.uniform(min_len, max_len, batch_size).astype('int32')\n",
    "    else:\n",
    "        samples = lens\n",
    "\n",
    "    start_times = np.array([np.random.uniform(0, max_len - duration) for duration in lens])\n",
    "    x = np.zeros((batch_size, max_len, 1))\n",
    "    y = np.zeros((batch_size, 2))\n",
    "    t = np.zeros((batch_size, max_len, 1))\n",
    "    for i, s, l, n in zip(range(batch_size), start_times, lens, samples):\n",
    "        if async_sampling:\n",
    "            time_points = np.reshape(np.sort(np.random.uniform(s, s + l, n)), [-1, 1])\n",
    "        else:\n",
    "            time_points = np.reshape(np.arange(s, s + n * resolution, step=resolution), [-1, 1])\n",
    "            \n",
    "        if i < half_batch:  # positive\n",
    "            _tmp_x = np.squeeze(np.sin(time_points * 2 * np.pi / posTs[i]))\n",
    "            x[i, :len(_tmp_x), 0] = _tmp_x\n",
    "            t[i, :len(_tmp_x), 0] = np.squeeze(time_points)\n",
    "            y[i, 0] = 1.\n",
    "        else:\n",
    "            _tmp_x = np.squeeze(np.sin(time_points * 2 * np.pi / negTs[i - half_batch]))\n",
    "            x[i, :len(_tmp_x), 0] = _tmp_x\n",
    "            t[i, :len(_tmp_x), 0] = np.squeeze(time_points)\n",
    "            y[i, 1] = 1.\n",
    "\n",
    "    x = np.squeeze(np.stack([x, t], 2))\n",
    "\n",
    "    return x, y, samples, posTs, negTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x, y, samples, posTs, negTs = gen_async_sin(False, resolution=0.1, batch_size=2,\n",
    "                                             off_target_T = [1, 100],\n",
    "                                             on_target_T = [5, 6],\n",
    "                                             min_len=50,max_len=125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1250"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x[0,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1170.06170856,   603.65614742])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
